This page describes the NLP-steps that are done on the server on a weekly basis

= Analysis=

This application uses a analysis process to extract opionions from twitter-data. Because this analysis takes a long time to run (up to two seconds a tweet) we pre-calculate results on a weekly basis and provide these results to our web-interface. 
The analysis itself uses NLP-techniques and can be divided into the two main steps "analysis on tweet-level" and "clustering". 
In the "Analysis on Tweet-Level" each tweet is enriched with information that the "Clustering" that follows later. The two steps are further described below:


= "Analysis on Tweet-Level"=

As already mentionned this step is performed for each tweet that was collected by the [Crawler]. "Analysis on Tweet-Level" consists itself of the five steps:

  * Segmentation and twitter-specific POS-tagging with the ArktweetTagger (Quelle): Because the ArktweetTager is just trained on english texts and our use case refers to mostly german tweets the results of this step isn't statisfying. We use this step to detect emoticons, links and twitter-specific phenomenons like the use of '@' and '#'
  * POS-tagging with the OpenNLPPOSTagger (Quelle): This POS-Tager is also capable of German
  * POS-merging: The results of the ArktweetTager are replaced with the results from OpenNLPPOSTagger except the emoticons, links and twitter-specific phenomenons
  * [Sentiment-tagging] that enriches tokens with a sentiment value
  * simple Sense-Annotation that 

= "Clustering"=